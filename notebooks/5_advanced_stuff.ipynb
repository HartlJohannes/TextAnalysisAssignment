{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1:\n",
      "enron hou subject 2000 2001\n",
      "\n",
      "Topic 2:\n",
      "list email 2002 mailing wrote\n",
      "\n",
      "Topic 3:\n",
      "linux list irish iluglinuxie maintainer\n",
      "\n",
      "Topic 4:\n",
      "university language linguistics email information\n",
      "\n",
      "Topic 5:\n",
      "enron company energy power 2001\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hartl\\AppData\\Local\\Temp\\ipykernel_29620\\313117043.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  safe_df['Topic'] = topic_results.argmax(axis=1) + 1  # Add 1 to make topics 1-indexed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Email Text  Topic\n",
      "1      reduplicative constructions polarity moravscik...      4\n",
      "4                                      url date supplied      3\n",
      "6      6 15 00 revision robin volumes forwarded choks...      1\n",
      "7      enbridge buys koch east texas midstream assets...      5\n",
      "9      call papers linguistics session mla call paper...      4\n",
      "...                                                  ...    ...\n",
      "12658  enron case studies eric number case studies en...      1\n",
      "12663  whitelistingoriginal message glynn mailtodelta...      2\n",
      "12664  body backgroundimage url color 331f30 alink co...      1\n",
      "12665  wip report attached updated wip report week 08...      1\n",
      "12666  eugene leitl original comments context digital...      2\n",
      "\n",
      "[7755 rows x 2 columns]\n",
      "Topic 1:\n",
      "font 00 size pills td\n",
      "\n",
      "Topic 2:\n",
      "account money email bank security\n",
      "\n",
      "Topic 3:\n",
      "company statements information securities stock\n",
      "\n",
      "Topic 4:\n",
      "email free click money business\n",
      "\n",
      "Topic 5:\n",
      "http online website links viagra\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hartl\\AppData\\Local\\Temp\\ipykernel_29620\\313117043.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  phishing_df['Topic'] = topic_results.argmax(axis=1) + 1  # Add 1 to make topics 1-indexed\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Hartl\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Email Text  Topic\n",
      "0      settled hey link requested hope needed gotta r...      4\n",
      "2      complete free service mortgage rates lower cre...      4\n",
      "3      receiving letter expressed interest receiving ...      4\n",
      "5      give partner pleasure girlfriend loves results...      4\n",
      "8                                       cheerries remove      5\n",
      "...                                                  ...    ...\n",
      "12656  trouble computer problems computeras part nati...      4\n",
      "12659  girl happy girl unsatisfied potency wait finds...      5\n",
      "12660  utf 8 oprah r utf 8 olex replicas real reprodu...      5\n",
      "12661  copy dvd movies click free softwarecopy dvd mo...      4\n",
      "12662  top quality prescription hardin curiosity culv...      5\n",
      "\n",
      "[4912 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hartl\\AppData\\Local\\Temp\\ipykernel_29620\\313117043.py:54: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  safe_df['Sentiment Scores'] = safe_df['Email Text'].apply(lambda text: sid.polarity_scores(text))\n",
      "C:\\Users\\Hartl\\AppData\\Local\\Temp\\ipykernel_29620\\313117043.py:55: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  safe_df['Sentiment Scores'] = safe_df['Sentiment Scores'].apply(lambda score_dict: score_dict['compound'])\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['Sentiment Score'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 57\u001b[0m\n\u001b[0;32m     54\u001b[0m safe_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSentiment Scores\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m safe_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEmail Text\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m text: sid\u001b[38;5;241m.\u001b[39mpolarity_scores(text))\n\u001b[0;32m     55\u001b[0m safe_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSentiment Scores\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m safe_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSentiment Scores\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m score_dict: score_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompound\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43msafe_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEmail Text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSentiment Score\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# Optional: Visualize sentiment scores\u001b[39;00m\n\u001b[0;32m     60\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\Hartl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Hartl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Hartl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['Sentiment Score'] not in index\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv(\"../data/processed/train_emails.csv\")\n",
    "safe_df = df[df['Email Type'] == 'Safe Email']\n",
    "phishing_df = df[df['Email Type'] == 'Phishing Email']\n",
    "\n",
    "safe_vectorizer = CountVectorizer()\n",
    "safe_X = safe_vectorizer.fit_transform(safe_df['Email Text'])\n",
    "\n",
    "phishing_vectorizer = CountVectorizer()\n",
    "phishing_X = phishing_vectorizer.fit_transform(phishing_df['Email Text'])\n",
    "\n",
    "num_topics = 5\n",
    "\n",
    "safe_lda = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "safe_lda.fit(safe_X)\n",
    "\n",
    "phishing_lda = LatentDirichletAllocation(n_components=num_topics, random_state=42)\n",
    "phishing_lda.fit(phishing_X)\n",
    "\n",
    "def display_topics(model, feature_names, no_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(f\"Topic {topic_idx + 1}:\")\n",
    "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-no_top_words - 1:-1]]))\n",
    "        print()\n",
    "\n",
    "no_top_words = 5  # Adjust the number of top words to display per topic\n",
    "feature_names = safe_vectorizer.get_feature_names_out()\n",
    "display_topics(safe_lda, feature_names, no_top_words)\n",
    "\n",
    "# Assign topics to each document\n",
    "topic_results = safe_lda.transform(safe_X)\n",
    "safe_df['Topic'] = topic_results.argmax(axis=1) + 1  # Add 1 to make topics 1-indexed\n",
    "print(safe_df[['Email Text', 'Topic']])\n",
    "\n",
    "no_top_words = 5  # Adjust the number of top words to display per topic\n",
    "feature_names = phishing_vectorizer.get_feature_names_out()\n",
    "display_topics(phishing_lda, feature_names, no_top_words)\n",
    "\n",
    "# Assign topics to each document\n",
    "topic_results = phishing_lda.transform(phishing_X)\n",
    "phishing_df['Topic'] = topic_results.argmax(axis=1) + 1  # Add 1 to make topics 1-indexed\n",
    "print(phishing_df[['Email Text', 'Topic']])\n",
    "\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "safe_df['Sentiment Scores'] = safe_df['Email Text'].apply(lambda text: sid.polarity_scores(text))\n",
    "safe_df['Sentiment Scores'] = safe_df['Sentiment Scores'].apply(lambda score_dict: score_dict['compound'])\n",
    "\n",
    "print(safe_df[['Email Text', 'Sentiment Score']])\n",
    "\n",
    "# Optional: Visualize sentiment scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(safe_df.index, safe_df['Sentiment Score'], color='skyblue')\n",
    "plt.title('Sentiment Analysis of Emails')\n",
    "plt.xlabel('Email Index')\n",
    "plt.ylabel('Sentiment Score')\n",
    "plt.xticks(safe_df.index, safe_df['Email Type'], rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "phishing_df['Sentiment Scores'] = phishing_df['Email Text'].apply(lambda text: sid.polarity_scores(text))\n",
    "phishing_df['Sentiment Scores'] = phishing_df['Sentiment Scores'].apply(lambda score_dict: score_dict['compound'])\n",
    "\n",
    "print(phishing_df[['Email Text', 'Sentiment Score']])\n",
    "\n",
    "# Optional: Visualize sentiment scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(phishing_df.index, phishing_df['Sentiment Score'], color='skyblue')\n",
    "plt.title('Sentiment Analysis of Emails')\n",
    "plt.xlabel('Email Index')\n",
    "plt.ylabel('Sentiment Score')\n",
    "plt.xticks(phishing_df.index, phishing_df['Email Type'], rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
